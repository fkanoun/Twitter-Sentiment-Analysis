{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "EI-__XxCnyAZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f130e94d-9115-4b0f-b186-ba78d9be34fe"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation\n",
        "from keras.layers.embeddings import Embedding\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "lODwNtIznyAg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# data_folder = './twitter-datasets/'\n",
        "data_folder = './'\n",
        "\n",
        "\n",
        "# Reading the data\n",
        "positive_path = os.path.join(data_folder,'train_pos.txt')\n",
        "negative_path = os.path.join(data_folder,'train_neg.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aFXbM7xNnyAj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lines_positive = [line.rstrip('\\n') for line in open(positive_path)]\n",
        "lines_negative = [line.rstrip('\\n') for line in open(negative_path)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pgXY0XienyAl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data preparation"
      ]
    },
    {
      "metadata": {
        "id": "7rkgBO-LnyAn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Create DF"
      ]
    },
    {
      "metadata": {
        "id": "sDz8kpq0nyAn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "31510614-035a-4f77-e2b3-37a9014fd922"
      },
      "cell_type": "code",
      "source": [
        "# Create dataFrame from positive tweets and give them value 1 as a sentiment\n",
        "data_pos = pd.DataFrame({\"tweets\": lines_positive,\n",
        "                      \"sentiment\":np.ones(len(lines_positive))\n",
        "                      })\n",
        "\n",
        "# Create dataFrame from negative tweets and give them value 0 as a sentiment\n",
        "data_neg = pd.DataFrame({\"tweets\": lines_negative,\n",
        "                      \"sentiment\":np.zeros(len(lines_negative))\n",
        "                      })\n",
        "# Concat both of them\n",
        "data = pd.concat([data_pos,data_neg],axis=0).reset_index().drop(columns=['index'])\n",
        "\n",
        "# Shuffle everything so that we don't have all the positives in one cluster and all the negatives in another\n",
        "data = data.sample(frac=1).reset_index(drop=True)\n",
        "data.head()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>just realised that my original idea would've b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>bored , rt for a shout out follow for a follow...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>the art of racing in the rain lp ( paperback e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>i had a really good monday ! i was happy all d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>mah eyez ! ! ! shit mannn d thing dem swell up...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment                                             tweets\n",
              "0        0.0  just realised that my original idea would've b...\n",
              "1        1.0  bored , rt for a shout out follow for a follow...\n",
              "2        0.0  the art of racing in the rain lp ( paperback e...\n",
              "3        1.0  i had a really good monday ! i was happy all d...\n",
              "4        0.0  mah eyez ! ! ! shit mannn d thing dem swell up..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "metadata": {
        "id": "9l5jQ-j6nyAr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Clean up the text"
      ]
    },
    {
      "metadata": {
        "id": "rGRDa3zDnyAs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "8511b6b5-c489-4c40-b260-4defd1f67824"
      },
      "cell_type": "code",
      "source": [
        "# Remove <anything> from tweets.\n",
        "data['tweets'].replace(regex=True,inplace=True,to_replace=r'<.*?>',value=r'')\n",
        "data.head()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>just realised that my original idea would've b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>bored , rt for a shout out follow for a follow...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>the art of racing in the rain lp ( paperback e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>i had a really good monday ! i was happy all d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>mah eyez ! ! ! shit mannn d thing dem swell up...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment                                             tweets\n",
              "0        0.0  just realised that my original idea would've b...\n",
              "1        1.0  bored , rt for a shout out follow for a follow...\n",
              "2        0.0  the art of racing in the rain lp ( paperback e...\n",
              "3        1.0  i had a really good monday ! i was happy all d...\n",
              "4        0.0  mah eyez ! ! ! shit mannn d thing dem swell up..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "metadata": {
        "id": "FyRzwQBKnyAu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = data['tweets'].tolist()\n",
        "y =  data['sentiment'].tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UMjhi3-wnyAy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Use tokenizer\n",
        "### From words to numbers"
      ]
    },
    {
      "metadata": {
        "id": "_OTXFFPDnyA0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# map words to numbers\n",
        "vocab_size = 100000\n",
        "tokenizer = Tokenizer(num_words=vocab_size)\n",
        "tokenizer.fit_on_texts(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qNXNu_mgnyA3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5884de9c-f42f-4637-f984-0ad71a69a681"
      },
      "cell_type": "code",
      "source": [
        "num_words = len(tokenizer.word_index)\n",
        "num_words"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "103085"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "metadata": {
        "id": "pdKLhlKLnyA_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data['length'] = data['tweets'].str.split().apply(len)\n",
        "max_tokens = data['length'].max()\n",
        "max_tokens = int(max_tokens/2)\n",
        "\n",
        "X = np.array(sequence.pad_sequences(tokenizer.texts_to_sequences(X), maxlen=max_tokens, padding='pre'))\n",
        "\n",
        "# Split train test\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gbpTZCZ7nyBP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### From numbers to words"
      ]
    },
    {
      "metadata": {
        "id": "Dvlgrqg4nyBQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def numbers_to_string(number_array, tokenizer):\n",
        "    \n",
        "    ''' \n",
        "    Transforms tokens to words\n",
        "    :param number_array: The numbers array to transform\n",
        "    :param tokenizer: The tokenizer used\n",
        "\n",
        "    :return: the original text\n",
        "    :rtype: String\n",
        "    '''\n",
        "        \n",
        "    indices = tokenizer.word_index\n",
        "    # Create a dict that mapes numbers to their respective words\n",
        "    inverse_map = dict(zip(indices.values(), indices.keys()))\n",
        "        \n",
        "    # Maps the numbers back to words.\n",
        "    words = []\n",
        "    for number in number_array:\n",
        "        if number != 0: # !=0 is to remove the padding\n",
        "            words.append(inverse_map[number])\n",
        "    \n",
        "    # Concatenate all words.\n",
        "    text = \" \".join(words)\n",
        "\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oWa8epd1nyBV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "62bba682-827b-42e8-b4e6-89069980992d"
      },
      "cell_type": "code",
      "source": [
        "numbers_to_string(X_train[0],tokenizer)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'bout 75 80 a piece from the looks of it rt my legs weigh a lot'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "metadata": {
        "id": "A3J-Vy2YnyBa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Neural Network"
      ]
    },
    {
      "metadata": {
        "id": "IrFZSBwx-fTj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Kbk-udEWnyBc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        },
        "outputId": "0c508ff0-0832-41bc-f6ce-8364fce98984"
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(num_words, 32, input_length=max_tokens))\n",
        "model.add(Conv1D(filters=128, kernel_size=5, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv1D(filters=64, kernel_size=6, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv1D(filters=32, kernel_size=7, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv1D(filters=32, kernel_size=8, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Saves the model after each epoch to study overfitting and optimal epochs\n",
        "checkpointer = ModelCheckpoint('weights.{epoch:01d}.hdf5', monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
        "\n",
        "epochs = 3\n",
        "\n",
        "history = model.fit(X_train, y_train, batch_size=128, verbose=1, validation_split=0.2, epochs=epochs, callbacks=[checkpointer])\n"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_19 (Embedding)     (None, 31, 32)            3298720   \n",
            "_________________________________________________________________\n",
            "conv1d_73 (Conv1D)           (None, 31, 128)           20608     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_73 (MaxPooling (None, 15, 128)           0         \n",
            "_________________________________________________________________\n",
            "dropout_73 (Dropout)         (None, 15, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_74 (Conv1D)           (None, 15, 64)            49216     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_74 (MaxPooling (None, 7, 64)             0         \n",
            "_________________________________________________________________\n",
            "dropout_74 (Dropout)         (None, 7, 64)             0         \n",
            "_________________________________________________________________\n",
            "conv1d_75 (Conv1D)           (None, 7, 32)             14368     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_75 (MaxPooling (None, 3, 32)             0         \n",
            "_________________________________________________________________\n",
            "dropout_75 (Dropout)         (None, 3, 32)             0         \n",
            "_________________________________________________________________\n",
            "conv1d_76 (Conv1D)           (None, 3, 32)             8224      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_76 (MaxPooling (None, 1, 32)             0         \n",
            "_________________________________________________________________\n",
            "dropout_76 (Dropout)         (None, 1, 32)             0         \n",
            "_________________________________________________________________\n",
            "flatten_19 (Flatten)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 3,391,169\n",
            "Trainable params: 3,391,169\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 128000 samples, validate on 32000 samples\n",
            "Epoch 1/3\n",
            "128000/128000 [==============================] - 100s 777us/step - loss: 0.4494 - acc: 0.7806 - val_loss: 0.3897 - val_acc: 0.8183\n",
            "Epoch 2/3\n",
            "128000/128000 [==============================] - 95s 742us/step - loss: 0.3243 - acc: 0.8573 - val_loss: 0.3980 - val_acc: 0.8207\n",
            "Epoch 3/3\n",
            "128000/128000 [==============================] - 95s 740us/step - loss: 0.2353 - acc: 0.9017 - val_loss: 0.4467 - val_acc: 0.8118\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Bi_Tz7-uEcf6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0ae45648-24da-491b-a3b1-bcffb9ef9d0e"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model   \n",
        "\n",
        "accuracies = []\n",
        "for i in range(1,epochs+1):\n",
        "  path = 'weights.'+str(i)+'.hdf5'\n",
        "  model = load_model(path)\n",
        "  result = model.evaluate(X_test, y_test, verbose=0)\n",
        "  accuracies.append(result[1])\n",
        "  \n",
        "accuracies"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.818975, 0.819475, 0.81195]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "metadata": {
        "id": "VT1kc8UInyBs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}