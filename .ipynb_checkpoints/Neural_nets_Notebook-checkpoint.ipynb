{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('full_preprocessed_data.csv')\n",
    "df = df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 32\n",
    "vocabulary_size = 100000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocabulary_size)\n",
    "tokenizer.fit_on_texts(df['tweets'])\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(df['tweets'])\n",
    "X = pad_sequences(sequences, maxlen=max_length)\n",
    "y = list(df.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_lstm(X,\n",
    "                     y,\n",
    "                     filepath=\"LSTM_best_weights.hdf5\",\n",
    "                     callbacks_list=[\n",
    "                         ModelCheckpoint(\n",
    "                             'LSTM_best_weights.hdf5',\n",
    "                             monitor='val_acc',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             mode='max'),\n",
    "                         EarlyStopping(\n",
    "                             monitor='val_acc', patience=3, mode='max')\n",
    "                     ],\n",
    "                     Embedding_size=200,\n",
    "                     batch_size=16384,\n",
    "                     validation_split=0.04,\n",
    "                     epochs=100):\n",
    "    \"\"\"\n",
    "    Create the model for a Long Short-Term Memory Network\n",
    "\n",
    "    INPUT:\n",
    "        X : Multidimensional list - The traning features\n",
    "        y : list                  - The traning results\n",
    "        callbacks_list :          - The callback options for the model\n",
    "        Embedding_size            - The size of the embedding \n",
    "        batch_size                - The size of the batch in the neural network\n",
    "        validation_split          - The validation_test split\n",
    "        epochs                    - The number of epochs\n",
    "        \n",
    "\n",
    "    OUTPUT:\n",
    "        Returns the model trained and the history of the training\n",
    "    \"\"\"\n",
    "\n",
    "    model_lstm = Sequential()\n",
    "    model_lstm.add(\n",
    "        Embedding(vocabulary_size, Embedding_size, input_length=max_length))\n",
    "    model_lstm.add(LSTM(Embedding_size, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model_lstm.add(Dense(1, activation='sigmoid'))\n",
    "    model_lstm.compile(\n",
    "        loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    history = model_lstm.fit(\n",
    "        X,\n",
    "        y,\n",
    "        validation_split=validation_split,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=callbacks_list)\n",
    "\n",
    "    return model_lstm, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 9s 2s/step - loss: 0.6921 - acc: 0.7500 - val_loss: 0.6915 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 1.00000, saving model to LSTM_best_weights.hdf5\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 2s 406ms/step - loss: 0.6813 - acc: 1.0000 - val_loss: 0.6959 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 1.00000\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 2s 419ms/step - loss: 0.6664 - acc: 1.0000 - val_loss: 0.7037 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 1.00000\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 1s 299ms/step - loss: 0.6525 - acc: 1.0000 - val_loss: 0.7188 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 1.00000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<keras.engine.sequential.Sequential at 0xb2def6d68>,\n",
       " <keras.callbacks.History at 0xb33123e80>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_model_lstm(X, y)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
